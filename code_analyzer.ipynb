{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "import base64\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from langchain import OpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        config = dotenv_values('.env')\n",
    "        openai.api_key = config['OPENAI_API_KEY']\n",
    "        os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']\n",
    "\n",
    "        # Paths and patterns\n",
    "        self.dir_path = config['LOCAL_REPO_PATH']\n",
    "        self.file_patterns = ['*.json', '*.txt', '*.py', '*.md']\n",
    "        self.is_local = True\n",
    "        if config['LOCAL_REPO'] == 'False':\n",
    "            self.is_local = False\n",
    "        self.github_repo = config['GITHUB_REPO']\n",
    "\n",
    "        repo_metadata = self.github_repo.split(\"github.com/\")[-1]\n",
    "        self.owner, self.repo_name = repo_metadata.split(\"/\")\n",
    "        response = requests.get(f\"https://api.github.com/repos/\"\n",
    "                                f\"{self.owner}/{self.repo_name}\")\n",
    "\n",
    "        self.default_branch = 'master'\n",
    "        if response.status_code == 200:\n",
    "            repo_info_endpoint = f\"https://api.github.com/repos/{self.owner}/{self.repo_name}\"\n",
    "            self.default_branch = (\n",
    "                requests.get(repo_info_endpoint).json()['default_branch']\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Analyzer:\n",
    "    main_prompt = \"\"\"\n",
    "    Firstly, give the following text an informative title.\n",
    "    Then, on a new line, write a 75-100 word summary of the following text:\n",
    "    {text}\n",
    "    Return your answer in the following format:\n",
    "    Title | Summary...\n",
    "    e.g.\n",
    "    Why Artificial Intelligence is Good | AI can make humans more productive by\n",
    "    automating many repetitive processes.\n",
    "    TITLE AND CONCISE SUMMARY:\n",
    "    \"\"\"\n",
    "\n",
    "    summarize_prompt = \"\"\"Write a detailed summary on the structure of the provided\n",
    "       content which contains code from selected files from a Github repository, which\n",
    "       deploys a chatbot system in Microsoft Azure. Please list all necessary details\n",
    "       which can be extrapolated later to specific guidelines how to reverse engineer\n",
    "       the repository. I am specifically looking for answers on:\n",
    "       i. the specific steps to deploy this resource? Please list all the files that\n",
    "       contain the specific tasks that automate the deployment!\n",
    "       ii. relevant files and code sections that I need to alter in case I want to\n",
    "       adjust the overall tool of the repository for my use case. Please list all\n",
    "       files and name the code sections.\n",
    "       iii. the detailed steps that need to be performed in order to adjust this\n",
    "       repository as a project template for customized deployments.:\n",
    "       {text}\n",
    "       \"\"\"\n",
    "\n",
    "    config = Config()\n",
    "\n",
    "    def __init__(self, file, content):\n",
    "        self.map_llm = OpenAI(temperature=0, model_name='text-davinci-003')\n",
    "        self.file = file\n",
    "        self.content = content\n",
    "\n",
    "    @staticmethod\n",
    "    def get_files_from_dir():\n",
    "        \"\"\"\n",
    "        Function to get files from local directory\n",
    "\n",
    "        \"\"\"\n",
    "        files_list = []\n",
    "        is_local = Analyzer.config.is_local\n",
    "        file_patterns = Analyzer.config.file_patterns\n",
    "        github_repo = Analyzer.config.github_repo\n",
    "        dir_path = Analyzer.config.dir_path\n",
    "        owner = Analyzer.config.owner\n",
    "        repo_name = Analyzer.config.repo_name\n",
    "        default_branch = Analyzer.config.default_branch\n",
    "\n",
    "        if is_local:\n",
    "            for pattern in file_patterns:\n",
    "                files_list.extend(glob.glob(dir_path + '/' + pattern,\n",
    "                                            recursive=True))\n",
    "        else:\n",
    "\n",
    "            all_files_endpoint = (\n",
    "                f\"https://api.github.com/repos/{owner}/\"\n",
    "                f\"{repo_name}/git/trees/{default_branch}?recursive=1\")\n",
    "\n",
    "            response = requests.get(all_files_endpoint)\n",
    "            if response.status_code == 200:\n",
    "                repo = response.json()\n",
    "                if repo.get('tree') is not None:\n",
    "                    tree = repo.get('tree')\n",
    "                    files_list = [\n",
    "                        item['path'] for item in tree\n",
    "                        if f\"*.{item['path'].split('.')[-1]}\" in file_patterns\n",
    "                    ]\n",
    "                else:\n",
    "                    print(\"Repository tree is empty\")\n",
    "            else:\n",
    "                print(f\"Repository cannot bee accessed {github_repo}\")\n",
    "        return files_list\n",
    "\n",
    "    @staticmethod\n",
    "    def read_files(file_paths):\n",
    "        \"\"\"\n",
    "        Function to read content of the files\n",
    "        \"\"\"\n",
    "        contents_dict = {}\n",
    "        is_local = Analyzer.config.is_local\n",
    "\n",
    "        if is_local:\n",
    "            for file_path in file_paths:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    contents_dict[file_path] = f.read()\n",
    "        else:\n",
    "            owner = Analyzer.config.owner\n",
    "            repo_name = Analyzer.config.repo_name\n",
    "            for file_path in file_paths:\n",
    "                file_content_api = (\n",
    "                    f'https://api.github.com/repos/{owner}/{repo_name}/contents/{file_path}'\n",
    "                )\n",
    "                response = requests.get(file_content_api)\n",
    "                if response.status_code == 200:\n",
    "                    contents_dict[file_path] = (\n",
    "                        base64.b64decode(response.json()['content']).decode(\n",
    "                            'UTF-8')\n",
    "                    )\n",
    "        return contents_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def get_chunks_from_text(text, num_chunks=10):\n",
    "        \"\"\"\n",
    "        Function to break a large text into chunks\n",
    "        \"\"\"\n",
    "\n",
    "        words = text.split()\n",
    "        words_per_chunk = len(words) // num_chunks\n",
    "        chunks_list = []\n",
    "        for i in range(0, len(words), words_per_chunk):\n",
    "            chunk = ' '.join(words[i:i + words_per_chunk])\n",
    "            chunks_list.append(chunk)\n",
    "        return chunks_list\n",
    "\n",
    "    def summarize_chunks(self, chunks_list, template):\n",
    "        \"\"\"\n",
    "        Function to summarize chunks_list using OpenAI\n",
    "        \"\"\"\n",
    "\n",
    "        llm_chain = LLMChain(llm=self.map_llm, prompt=template)\n",
    "        summaries = []\n",
    "        for chunk in chunks_list:\n",
    "            chunk_summary = llm_chain.apply([{'text': chunk}])\n",
    "            summaries.append(f\" {chunk_summary}\")\n",
    "        return summaries\n",
    "\n",
    "    @staticmethod\n",
    "    def create_similarity_matrix(chunks_list):\n",
    "        \"\"\"\n",
    "        Function to calculate similarity matrix\n",
    "        \"\"\"\n",
    "\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        vectors = vectorizer.fit_transform(\n",
    "            [' '.join(chunk.split()[:200]) for chunk in chunks_list])\n",
    "        return cosine_similarity(vectors)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_topics(similarity_matrix_, num_topics=5):\n",
    "        \"\"\"\n",
    "        Get the topics from the similarity matrix\n",
    "        \"\"\"\n",
    "        distances = 1 - similarity_matrix_\n",
    "        kmeans = KMeans(n_clusters=num_topics).fit(distances)\n",
    "        clusters = kmeans.labels_\n",
    "        chunk_topics = [np.where(clusters == i)[0] for i in range(num_topics)]\n",
    "        return chunk_topics\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_title_summary_results(results):\n",
    "        \"\"\"\n",
    "        Function to parse title and summary results\n",
    "        \"\"\"\n",
    "\n",
    "        outputs = []\n",
    "        for result in results:\n",
    "\n",
    "            result = result.replace('\\n', '')\n",
    "            if '|' in result:\n",
    "                processed = {'title': result.split('|')[0],\n",
    "                             'summary': result.split('|')[1][1:]\n",
    "                             }\n",
    "            elif ':' in result:\n",
    "                processed = {'title': result.split(':')[0],\n",
    "                             'summary': result.split(':')[1][1:]\n",
    "                             }\n",
    "            elif '-' in result:\n",
    "                processed = {'title': result.split('-')[0],\n",
    "                             'summary': result.split('-')[1][1:]\n",
    "                             }\n",
    "            else:\n",
    "                processed = {'title': '',\n",
    "                             'summary': result\n",
    "                             }\n",
    "            outputs.append(processed)\n",
    "        return outputs\n",
    "\n",
    "    def summarize_stage(self, chunks_list, topics_list):\n",
    "        \"\"\"\n",
    "        Function to summarize the stage\n",
    "        \"\"\"\n",
    "\n",
    "        print(f'Start time: {datetime.now()}')\n",
    "\n",
    "        # Prompt to get title and summary for each topic\n",
    "\n",
    "        map_prompt = PromptTemplate(template=Analyzer.summarize_prompt,\n",
    "                                    input_variables=[\"text\"])\n",
    "\n",
    "        # Define the LLMs\n",
    "        map_llm_chain = LLMChain(llm=self.map_llm, prompt=map_prompt)\n",
    "\n",
    "        summaries = []\n",
    "        for i in range(len(topics_list)):\n",
    "            topic_summaries = []\n",
    "            for topic in topics_list[i]:\n",
    "                map_llm_chain_input = [{'text': chunks_list[topic]}]\n",
    "                # Run the input through the LLM chain (works in parallel)\n",
    "                map_llm_chain_results = map_llm_chain.apply(map_llm_chain_input)\n",
    "                stage_1_outputs = Analyzer.parse_title_summary_results(\n",
    "                    [e['text'] for e in map_llm_chain_results])\n",
    "                # Split the titles and summaries\n",
    "                topic_summaries.append(stage_1_outputs[0]['summary'])\n",
    "            # Concatenate all summaries of a topic\n",
    "            summaries.append(' '.join(topic_summaries))\n",
    "\n",
    "        print(f'Stage done time {datetime.now()}')\n",
    "\n",
    "        return summaries\n",
    "\n",
    "    @staticmethod\n",
    "    def get_prompt_template(template):\n",
    "        return PromptTemplate(template=template,\n",
    "                              input_variables=['text'])\n",
    "\n",
    "    def analyze_file(self):\n",
    "        print(f'Processing {self.file}...')\n",
    "\n",
    "        print(f\"Get chunks from {self.file}...\")\n",
    "        chunks = Analyzer.get_chunks_from_text(self.content)\n",
    "        print(\"Chunks generated!\")\n",
    "\n",
    "        # Summarize chunks\n",
    "        print(\"Summarizing chunks...\")\n",
    "        chunk_summaries = (\n",
    "            self.summarize_chunks(\n",
    "                chunks,\n",
    "                self.get_prompt_template(Analyzer.main_prompt))\n",
    "        )\n",
    "        print(\"Chunks summarized!\")\n",
    "\n",
    "        # Create similarity matrix\n",
    "        print(\"Creating similarity matrix...\")\n",
    "        similarity_matrix = Analyzer.create_similarity_matrix(chunks)\n",
    "        print(\"Similarity matrix created!\")\n",
    "\n",
    "        # Get topics\n",
    "        print(\"Getting topics...\")\n",
    "        topics = Analyzer.get_topics(similarity_matrix)\n",
    "        print(\"Topics are got!\")\n",
    "\n",
    "        # Summarize stage\n",
    "        print(\"Get stage summary...\")\n",
    "        stage_summary = self.summarize_stage(chunk_summaries, topics)\n",
    "\n",
    "        print(f'Summary for {self.file}:\\n{stage_summary}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Main script\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch files\n",
    "    files = Analyzer.get_files_from_dir()\n",
    "\n",
    "    # Iterate over files and process\n",
    "    for _file, _content in Analyzer.read_files(files).items():\n",
    "        code_analyzer = Analyzer(_file, _content)\n",
    "        code_analyzer.analyze_file()\n",
    "\n",
    "    print('All files processed.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
